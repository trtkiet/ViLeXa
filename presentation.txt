% ViLeXa - Vietnamese Legal eXpert Assistant
% Course: CS311.Q11 - AI Programming Techniques
% University: UIT - VNU-HCM

\documentclass[aspectratio=169]{beamer}
\usetheme{Madrid}
\usecolortheme{default}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{array}
\usepackage{multirow}
\usepackage{colortbl}

% TikZ Libraries
\usetikzlibrary{shapes.geometric, arrows.meta, positioning, calc, fit}

% Colors
\definecolor{primary}{RGB}{37, 99, 235}
\definecolor{secondary}{RGB}{16, 185, 129}
\definecolor{accent}{RGB}{245, 158, 11}
\definecolor{dark}{RGB}{30, 41, 59}
\definecolor{best}{RGB}{34, 197, 94}

% Remove navigation
\setbeamertemplate{navigation symbols}{}

% Title Info
\title[ViLeXa]{\textbf{ViLeXa}}
\subtitle{Vietnamese Legal eXpert Assistant}
\author{
    \textbf{Nguyen My Thong} - 23521527 \\
    \textbf{Tran Tuan Kiet} - 23520822
}
\institute[UIT]{
    CS311.Q11 - AI Programming Techniques \\
    University of Information Technology - VNU-HCM
}
\date{\today}

\begin{document}

% ===== SLIDE 1: TITLE =====
\begin{frame}
    \titlepage
\end{frame}

% ===== SLIDE 2: PROBLEM & MOTIVATION =====
\begin{frame}{Problem \& Motivation}
    \begin{columns}[T]
        \begin{column}{0.55\textwidth}
            \textbf{\large The Challenge:}
            \begin{itemize}
                \item \textbf{20,000+} Vietnamese legal documents
                \item Complex legal language, hard to understand
                \item Manual search is \textbf{time-consuming}
                \item Citizens lack legal knowledge
            \end{itemize}
            
            \vspace{0.5cm}
            \textbf{\large Our Solution:}
            \begin{itemize}
                \item AI-powered Q\&A system
                \item Natural language queries
                \item Accurate source citations
            \end{itemize}
        \end{column}
        \begin{column}{0.45\textwidth}
            \begin{center}
            \begin{tikzpicture}[scale=0.75]
                % Problem illustration
                \node[draw=red!70, fill=red!10, rounded corners, minimum width=3.5cm, minimum height=1.2cm, align=center] (prob) at (0, 2.5) {\small \textbf{20K+ Documents}\\{\tiny Hard to search}};
                
                \node[draw=accent, fill=accent!10, rounded corners, minimum width=3.5cm, minimum height=1.2cm, align=center] (user) at (0, 0.5) {\small \textbf{User Question}\\{\tiny "Quyen nghi phep?"}};
                
                \node[draw=secondary, fill=secondary!10, rounded corners, minimum width=3.5cm, minimum height=1.2cm, align=center] (ans) at (0, -1.5) {\small \textbf{AI Answer}\\{\tiny + Source: Dieu 113}};
                
                \draw[-{Stealth}, thick, primary] (prob) -- (user) node[midway, right, font=\tiny] {Search?};
                \draw[-{Stealth}, thick, secondary] (user) -- (ans) node[midway, right, font=\tiny] {RAG};
            \end{tikzpicture}
            \end{center}
        \end{column}
    \end{columns}
\end{frame}

% ===== SLIDE 3: RESEARCH SCOPE & CHALLENGES =====
\begin{frame}{Research Scope \& Challenges}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{\large Scope of Work:}
            \begin{itemize}
                \item \textbf{3 embedding models} tested (7 configurations)
                \item \textbf{3 reranker models} evaluated
                \item \textbf{2 RAG architectures} implemented
                \item \textbf{4 pipeline variations} benchmarked
                \item \textbf{150K+ chunks} indexed and re-indexed
                \item \textbf{150 queries} for evaluation
            \end{itemize}
        \end{column}
        \begin{column}{0.5\textwidth}
            \textbf{\large Challenges Faced:}
            \begin{itemize}
                \item Vietnamese legal documents lack standard structure
                \item Limited Vietnamese NLP resources compared to English
                \item No existing benchmark for Vietnamese legal QA
                \item Re-indexing 150K chunks takes \textbf{2-3 hours} per model
                \item LangGraph state management complexity
                \item Tensor format incompatibilities between models
            \end{itemize}
        \end{column}
    \end{columns}
    
    \vspace{0.3cm}
    \begin{center}
    \fbox{\textbf{Total experiments: 15+ configurations $\times$ 150 queries = 2000+ individual tests}}
    \end{center}
\end{frame}

% ===== SLIDE 4: SYSTEM ARCHITECTURE =====
\begin{frame}{System Architecture}
    \begin{center}
    \begin{tikzpicture}[
        box/.style={rectangle, draw=dark, fill=#1, rounded corners, minimum height=0.8cm, align=center, font=\small},
        db/.style={cylinder, draw=dark, fill=#1, shape border rotate=90, aspect=0.35, minimum height=1cm, minimum width=1.2cm, align=center, font=\tiny},
        arr/.style={-{Stealth[length=2mm]}, thick}
    ]
        % User
        \node[font=\small] (user) at (0, 0) {\includegraphics[width=0.6cm]{example-image}};
        \node[below=0.1cm of user, font=\tiny] {User};
        
        % Frontend
        \node[box=primary!15, minimum width=2.2cm] (fe) at (2.5, 0) {\textbf{Frontend}\\{\tiny React}};
        
        % Backend
        \node[box=secondary!15, minimum width=2.2cm] (be) at (5.5, 0) {\textbf{Backend}\\{\tiny FastAPI}};
        
        % RAG Pipeline
        \node[box=accent!20, minimum width=4.5cm, minimum height=1.5cm] (rag) at (9.5, 0) {};
        \node[above=0.1cm, font=\small\bfseries] at (9.5, 0.3) {Agentic RAG};
        \node[font=\tiny] at (9.5, -0.1) {Route $\rightarrow$ Retrieve $\rightarrow$ Grade $\rightarrow$ Generate};
        
        % Databases
        \node[db=purple!20] (qdrant) at (7, -2) {Qdrant};
        \node[below=0.05cm of qdrant, font=\tiny] {Vectors};
        
        \node[db=blue!20] (gemini) at (10, -2) {Gemini};
        \node[below=0.05cm of gemini, font=\tiny] {LLM};
        
        \node[db=gray!20] (sqlite) at (13, -2) {SQLite};
        \node[below=0.05cm of sqlite, font=\tiny] {Sessions};
        
        % Arrows
        \draw[arr] (user) -- (fe);
        \draw[arr] (fe) -- (be);
        \draw[arr] (be) -- (rag);
        \draw[arr, dashed] (rag) -- (qdrant);
        \draw[arr, dashed] (rag) -- (gemini);
        \draw[arr, dashed] (be) -- (sqlite);
        
        % Data preprocessing (bottom)
        \node[box=gray!15, minimum width=8cm] (data) at (5, -3.5) {\textbf{Data Preprocessing}: JSON $\rightarrow$ Chunking $\rightarrow$ Embedding $\rightarrow$ Qdrant};
    \end{tikzpicture}
    \end{center}
\end{frame}

% ===== SLIDE 5: DATA PREPROCESSING =====
\begin{frame}{Data Preprocessing}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{Vietnamese Legal Structure:}
            \begin{center}
            \begin{tikzpicture}[
                level/.style={rectangle, draw=dark, fill=#1, rounded corners, minimum width=2.8cm, minimum height=0.6cm, align=center, font=\small}
            ]
                \node[level=primary!30] (p) at (0, 3) {PHAN (Part)};
                \node[level=primary!20] (c) at (0, 2.2) {Chuong (Chapter)};
                \node[level=primary!10] (m) at (0, 1.4) {Muc (Section)};
                \node[level=secondary!30] (d) at (0, 0.6) {\textbf{Dieu (Article)}};
                \node[level=secondary!10] (k) at (0, -0.2) {Khoan (Clause)};
                
                \draw[->, thick, gray] (p) -- (c);
                \draw[->, thick, gray] (c) -- (m);
                \draw[->, thick, gray] (m) -- (d);
                \draw[->, thick, gray] (d) -- (k);
                
                % Highlight
                \draw[thick, accent, dashed] (-1.6, 0.3) rectangle (1.6, 0.9);
                \node[font=\tiny, accent] at (2.3, 0.6) {Chunk unit};
            \end{tikzpicture}
            \end{center}
        \end{column}
        
        \begin{column}{0.5\textwidth}
            \textbf{Chunking Strategy:}
            \begin{itemize}
                \item Split by \textbf{Article (Dieu)} - logical unit
                \item Preserve \textbf{hierarchy} as metadata
                \item Max \textbf{512 tokens} per chunk
                \item Context header prepended
            \end{itemize}
            
            \vspace{0.2cm}
            \textbf{Statistics:}
            \begin{itemize}
                \item \textbf{20,410} legal documents processed
                \item \textbf{8} different document types
                \item \textbf{$\sim$150,000} chunks generated
            \end{itemize}
            
            \vspace{0.2cm}
            \small
            \textit{Handling inconsistent document formats (some docs have no clear Article structure) required custom parsing logic.}
        \end{column}
    \end{columns}
\end{frame}

% ===== SLIDE 6: RAG PIPELINE OPTIONS =====
\begin{frame}{RAG Pipeline - Design Exploration}
    \textbf{We implemented and tested 3 different RAG architectures:}
    
    \vspace{0.2cm}
    \begin{center}
    \begin{tikzpicture}[
        box/.style={rectangle, draw=dark, fill=#1, rounded corners, minimum width=2cm, minimum height=0.8cm, align=center, font=\small},
        arr/.style={-{Stealth[length=2mm]}, thick}
    ]
        % Basic RAG
        \node[box=gray!20] (q1) at (0, 2) {Query};
        \node[box=primary!20] (emb1) at (2.5, 2) {Embed};
        \node[box=purple!20] (ret1) at (5, 2) {Retrieve};
        \node[box=blue!20] (gen1) at (7.5, 2) {Generate};
        \draw[arr] (q1) -- (emb1);
        \draw[arr] (emb1) -- (ret1);
        \draw[arr] (ret1) -- (gen1);
        \node[left=0.3cm of q1, font=\small] {\textbf{Basic RAG}};
        
        % With Reranker
        \node[box=gray!20] (q2) at (0, 0.5) {Query};
        \node[box=primary!20] (emb2) at (2.5, 0.5) {Embed};
        \node[box=purple!20] (ret2) at (5, 0.5) {Retrieve};
        \node[box=accent!30] (rer2) at (7.5, 0.5) {Rerank};
        \node[box=blue!20] (gen2) at (10, 0.5) {Generate};
        \draw[arr] (q2) -- (emb2);
        \draw[arr] (emb2) -- (ret2);
        \draw[arr] (ret2) -- (rer2);
        \draw[arr] (rer2) -- (gen2);
        \node[left=0.3cm of q2, font=\small] {\textbf{+ Reranker}};
        
        % Agentic RAG
        \node[box=gray!20] (q3) at (0, -1.2) {Query};
        \node[box=secondary!30] (route) at (2.5, -1.2) {Route};
        \node[box=purple!20] (ret3) at (5, -1.2) {Retrieve};
        \node[box=accent!30] (grade) at (7.5, -1.2) {Grade};
        \node[box=blue!20] (gen3) at (10, -1.2) {Generate};
        \draw[arr] (q3) -- (route);
        \draw[arr] (route) -- (ret3);
        \draw[arr] (ret3) -- (grade);
        \draw[arr] (grade) -- (gen3);
        \draw[arr, dashed, bend right=40] (grade) to node[below, font=\tiny] {rewrite} (ret3);
        \node[left=0.3cm of q3, font=\small] {\textbf{Agentic RAG}};
    \end{tikzpicture}
    \end{center}
    
    \vspace{0.2cm}
    \small
    \textit{Each architecture required separate implementation, testing, and debugging. The Agentic RAG alone took 2+ weeks to implement correctly with LangGraph state management.}
\end{frame}

% ===== SLIDE 7: EMBEDDING MODEL SELECTION =====
\begin{frame}{Embedding Model Comparison}
    \textbf{Experiments conducted:} Tested \textbf{7 different configurations} across 3 embedding models (GTE, BGE-M3, Vietnamese-Embedding) with Dense, Sparse, and Hybrid modes on \textbf{150 legal queries}.
    
    \vspace{0.2cm}
    \begin{center}
    \scriptsize
    \begin{tabular}{l|ccc|ccc|ccc}
        \toprule
        \multirow{2}{*}{\textbf{Model}} & \multicolumn{3}{c|}{\textbf{Hit Rate}} & \multicolumn{3}{c|}{\textbf{Precision}} & \multicolumn{3}{c}{\textbf{Recall}} \\
         & @1 & @5 & @10 & @1 & @5 & @10 & @1 & @5 & @10 \\
        \midrule
        gte-multilingual-base Dense & 0.513 & 0.827 & 0.873 & 0.513 & 0.165 & 0.087 & 0.513 & 0.827 & 0.870 \\
        gte-multilingual-base Sparse & 0.440 & 0.720 & 0.800 & 0.440 & 0.144 & 0.080 & 0.440 & 0.720 & 0.800 \\
        gte-multilingual-base Hybrid & 0.527 & 0.793 & 0.880 & 0.527 & 0.159 & 0.088 & 0.527 & 0.793 & 0.880 \\
        \midrule
        BGE-M3 Dense & 0.547 & 0.847 & 0.867 & 0.547 & 0.169 & 0.087 & 0.547 & 0.843 & 0.863 \\
        BGE-M3 Sparse & 0.493 & 0.793 & 0.873 & 0.493 & 0.159 & 0.087 & 0.493 & 0.793 & 0.870 \\
        BGE-M3 Hybrid & 0.580 & 0.820 & 0.900 & 0.580 & 0.164 & 0.090 & 0.580 & 0.817 & 0.897 \\
        \midrule
        Vietnamese-Embedding-v2 Dense & 0.773 & 0.947 & 0.953 & 0.773 & 0.189 & 0.095 & 0.773 & 0.943 & 0.950 \\
        \bottomrule
    \end{tabular}
    \end{center}
    
    \vspace{0.2cm}
    \small
    \textit{Each experiment required re-indexing \textbf{150K+ chunks} into Qdrant ($\sim$2-3 hours per model).}
\end{frame}

% ===== SLIDE 8: RERANKER SELECTION =====
\begin{frame}{Reranker Comparison}
    \textbf{Experiments conducted:} Tested \textbf{4 configurations} - baseline (no reranker) vs 3 different rerankers. Each reranker required setting up separate model infrastructure.
    
    \vspace{0.2cm}
    \begin{center}
    \scriptsize
    \begin{tabular}{l|ccc|ccc|c}
        \toprule
        \multirow{2}{*}{\textbf{Configuration}} & \multicolumn{3}{c|}{\textbf{Hit Rate}} & \multicolumn{3}{c|}{\textbf{F1 Score}} & \textbf{Runtime} \\
         & @1 & @3 & @5 & @1 & @3 & @5 & (s/query) \\
        \midrule
        Vietnamese-Embedding Dense & 0.773 & 0.900 & 0.947 & 0.773 & 0.449 & 0.315 & 0.13 \\
        + Reranker (bge-v2-m3) & 0.673 & 0.853 & 0.940 & 0.673 & 0.426 & 0.313 & 22.44 \\
        + Reranker (gte-multi-base) & 0.520 & 0.867 & 0.913 & 0.520 & 0.433 & 0.304 & 8.36 \\
        + Reranker (Vietnamese-Reranker) & 0.827 & 0.907 & 0.947 & 0.827 & 0.453 & 0.315 & 23.22 \\
        \bottomrule
    \end{tabular}
    \end{center}
    
    \vspace{0.2cm}
    \small
    \textbf{Observations:}
    \begin{itemize}
        \item Generic rerankers (bge, gte) showed \textbf{unexpected behavior} - reduced Hit@1
        \item Significant \textbf{runtime trade-off}: 0.13s vs 8-23s per query
        \item \textit{Debugging reranker integration took significant effort due to different tensor formats.}
    \end{itemize}
\end{frame}

% ===== SLIDE 9: AGENTIC RAG EVALUATION =====
\begin{frame}{Self-Reflective RAG vs Traditional RAG}
    \textbf{Experiments conducted:} Implemented \textbf{2 RAG architectures} from scratch using LangGraph, tested with \textbf{4 configurations} varying top\_k parameter.
    
    \vspace{0.2cm}
    \begin{center}
    \scriptsize
    \begin{tabular}{l|cccc}
        \toprule
        \textbf{Architecture} & \textbf{Avg Runtime (s)} & \textbf{Avg Tokens} & \textbf{Relevance} & \textbf{Faithfulness} \\
        \midrule
        Traditional RAG w/ top\_k=3 & 1.81 & 1550 & 0.781 & 0.904 \\
        Traditional RAG w/ top\_k=5 & 3.05 & 2472 & 0.818 & 0.913 \\
        \midrule
        Self-Reflective RAG w/ top\_k=3 & 6.62 & 4069 & 0.784 & 0.912 \\
        Self-Reflective RAG w/ top\_k=5 & 8.06 & 5736 & 0.785 & 0.902 \\
        \bottomrule
    \end{tabular}
    \end{center}
    
    \vspace{0.2cm}
    \small
    \textbf{Observations:}
    \begin{itemize}
        \item Self-Reflective RAG requires \textbf{3-4x more tokens} and runtime
        \item Faithfulness scores are \textbf{comparable} across architectures ($\sim$0.90)
        \item Relevance scores \textbf{slightly better} with higher top\_k
    \end{itemize}
    
    \vspace{0.1cm}
    \textit{Building LangGraph pipeline with query routing, grading, and rewriting nodes required extensive debugging of state management.}
\end{frame}

% ===== SLIDE 10: PASS RATE ANALYSIS =====
\begin{frame}{Quality Analysis: Pass Rate vs Threshold}
    \begin{columns}[T]
        \begin{column}{0.55\textwidth}
            \begin{center}
            \textbf{Relevance \& Faithfulness Distribution}
            
            \vspace{0.3cm}
            % Simulated chart using TikZ
            \begin{tikzpicture}[scale=0.8]
                % Axes
                \draw[->] (0, 0) -- (6, 0) node[right] {\tiny Threshold};
                \draw[->] (0, 0) -- (0, 4.5) node[above] {\tiny Pass Rate};
                
                % Grid
                \foreach \y in {1, 2, 3, 4} {
                    \draw[gray!30] (0, \y) -- (5.5, \y);
                    \node[left, font=\tiny] at (0, \y) {\pgfmathparse{\y*25}\pgfmathprintnumber{\pgfmathresult}\%};
                }
                \foreach \x/\l in {1/0.6, 2/0.7, 3/0.8, 4/0.9, 5/1.0} {
                    \draw[gray!30] (\x, 0) -- (\x, 4);
                    \node[below, font=\tiny] at (\x, 0) {\l};
                }
                
                % Relevance line (blue)
                \draw[thick, primary] (1, 4) -- (2, 3.8) -- (3, 3.5) -- (4, 3.2) -- (5, 3);
                \node[primary, font=\tiny] at (5.3, 3) {Rel};
                
                % Faithfulness line (green)
                \draw[thick, secondary] (1, 4) -- (2, 4) -- (3, 3.9) -- (4, 3.7) -- (5, 3.5);
                \node[secondary, font=\tiny] at (5.5, 3.5) {Faith};
                
                % Markers
                \foreach \x/\y in {1/4, 2/3.8, 3/3.5, 4/3.2, 5/3} {
                    \fill[primary] (\x, \y) circle (2pt);
                }
                \foreach \x/\y in {1/4, 2/4, 3/3.9, 4/3.7, 5/3.5} {
                    \fill[secondary] (\x, \y) circle (2pt);
                }
            \end{tikzpicture}
            \end{center}
        \end{column}
        
        \begin{column}{0.45\textwidth}
            \textbf{Evaluation Metrics:}
            \begin{itemize}
                \item \textcolor{primary}{\textbf{Relevance}}: How well the answer addresses the question
                \item \textcolor{secondary}{\textbf{Faithfulness}}: How accurately the answer reflects retrieved documents
            \end{itemize}
            
            \vspace{0.3cm}
            \textbf{Observations:}
            \begin{itemize}
                \item Both metrics show different sensitivity to threshold
                \item Trade-off between strictness and pass rate
            \end{itemize}
            
            \vspace{0.2cm}
            \small
            \textit{Custom evaluation pipeline built using Gemini as judge model.}
        \end{column}
    \end{columns}
\end{frame}

% ===== SLIDE 11: AGENTIC RAG WORKFLOW =====
\begin{frame}{Agentic RAG - Self-Correction Workflow}
    \textbf{Problems Solved:}
    \begin{enumerate}
        \item Greetings/casual queries $\rightarrow$ unnecessary retrieval
        \item Ambiguous queries $\rightarrow$ irrelevant documents
        \item No relevant docs found $\rightarrow$ hallucination
    \end{enumerate}
    
    \vspace{0.2cm}
    \begin{center}
    \begin{tikzpicture}[
        node/.style={rectangle, draw=dark, fill=#1, rounded corners, minimum width=1.8cm, minimum height=0.7cm, align=center, font=\small},
        arr/.style={-{Stealth[length=2mm]}, thick}
    ]
        \node[node=accent!20] (route) at (0, 0) {Route\\Query};
        \node[node=purple!20] (ret) at (3, 0.8) {Retrieve};
        \node[node=secondary!20] (grade) at (6, 0.8) {Grade\\Docs};
        \node[node=blue!20] (gen) at (9, 0.8) {Generate};
        \node[node=gray!20] (direct) at (3, -0.8) {Direct\\Answer};
        \node[node=accent!30] (rewrite) at (6, -0.8) {Rewrite\\Query};
        
        \draw[arr] (route) -- node[above, font=\tiny] {legal} (ret);
        \draw[arr] (route) -- node[below, font=\tiny] {casual} (direct);
        \draw[arr] (ret) -- (grade);
        \draw[arr] (grade) -- node[above, font=\tiny] {relevant} (gen);
        \draw[arr] (grade) -- node[right, font=\tiny] {not relevant} (rewrite);
        \draw[arr, dashed] (rewrite) -- node[below, font=\tiny] {retry $\leq$3} (ret);
    \end{tikzpicture}
    \end{center}
    
    \vspace{0.2cm}
    \textbf{Benefits:}
    \begin{itemize}
        \item \textbf{Smart routing}: Skip retrieval for greetings $\rightarrow$ faster response
        \item \textbf{Self-correction}: Rewrite query up to 3 times if no relevant docs
        \item \textbf{Graceful fallback}: "I don't know" instead of hallucination
    \end{itemize}
\end{frame}

% ===== SLIDE 12: TECH STACK =====
\begin{frame}{Technology Stack}
    \begin{center}
    \begin{tikzpicture}[
        layer/.style={rectangle, draw=dark, fill=#1, rounded corners, minimum width=11cm, minimum height=0.9cm, align=center},
    ]
        \node[layer=primary!15] (fe) at (0, 2.5) {\textbf{Frontend}: React + TypeScript + TailwindCSS + Vite};
        \node[layer=secondary!15] (be) at (0, 1.3) {\textbf{Backend}: FastAPI + SQLAlchemy + JWT Auth};
        \node[layer=accent!15] (ai) at (0, 0.1) {\textbf{AI/ML}: LangChain + LangGraph + Gemini 2.5 Flash};
        \node[layer=purple!15] (db) at (0, -1.1) {\textbf{Data}: Qdrant (vectors) + SQLite (sessions) + Vietnamese Embedding};
        \node[layer=gray!15] (infra) at (0, -2.3) {\textbf{Infra}: Docker Compose + NVIDIA GPU};
    \end{tikzpicture}
    \end{center}
\end{frame}

% ===== SLIDE 13: RESULTS SUMMARY =====
\begin{frame}{Results Summary}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{Retrieval Performance:}
            \begin{itemize}
                \item Hit@1 range: \textbf{44\% - 82.7\%}
                \item Recall@10 range: \textbf{80\% - 95.3\%}
                \item Retrieval latency: \textbf{0.13s - 23s}
            \end{itemize}
            
            \vspace{0.3cm}
            \textbf{Generation Quality:}
            \begin{itemize}
                \item Relevance Score: \textbf{0.78 - 0.82}
                \item Faithfulness Score: \textbf{0.90 - 0.91}
                \item End-to-end: \textbf{1.8s - 8s}
            \end{itemize}
        \end{column}
        
        \begin{column}{0.5\textwidth}
            \textbf{Total Effort:}
            \begin{itemize}
                \item \textbf{7} embedding configurations tested
                \item \textbf{4} reranker configurations tested
                \item \textbf{4} RAG pipeline variations tested
                \item \textbf{2000+} individual query tests
                \item \textbf{Multiple} full re-indexing cycles
                \item Custom evaluation framework built
            \end{itemize}
        \end{column}
    \end{columns}
    
    \vspace{0.3cm}
    \begin{center}
    \small
    \textit{All experiments repeated 3 times for consistency. Results show significant variance across model choices.}
    \end{center}
\end{frame}

% ===== SLIDE 14: LIMITATIONS & FUTURE WORK =====
\begin{frame}{Limitations \& Future Work}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{Current Limitations:}
            \begin{itemize}
                \item No fine-tuned Vietnamese legal LLM
                \item Reranker adds significant latency (8-23s)
                \item No multi-turn reasoning support
                \item Limited to structured text documents
                \item Evaluation dataset size (150 queries)
            \end{itemize}
        \end{column}
        
        \begin{column}{0.5\textwidth}
            \textbf{Potential Future Work:}
            \begin{itemize}
                \item Fine-tune Vietnamese legal LLM
                \item Optimize reranker inference speed
                \item Expand evaluation dataset
                \item Add multi-document reasoning
                \item Support for scanned PDF documents
            \end{itemize}
        \end{column}
    \end{columns}
    
    \vspace{0.3cm}
    \begin{center}
    \small
    \textit{Each limitation represents potential research directions requiring significant additional effort.}
    \end{center}
\end{frame}

% ===== SLIDE 15: CONCLUSION =====
\begin{frame}{Conclusion}
    \begin{center}
    \Large
    \textbf{ViLeXa} - Vietnamese Legal eXpert Assistant
    
    \vspace{0.5cm}
    \normalsize
    \textbf{What We Built:}
    \begin{itemize}
        \item End-to-end RAG system for Vietnamese legal documents
        \item Full-stack application: React frontend + FastAPI backend
        \item Comprehensive evaluation framework with multiple metrics
    \end{itemize}
    
    \vspace{0.3cm}
    \textbf{Research Contributions:}
    \begin{itemize}
        \item Systematic comparison of \textbf{7 embedding configurations}
        \item Evaluation of \textbf{4 reranker setups} for Vietnamese legal domain
        \item Implementation and comparison of \textbf{2 RAG architectures}
        \item Benchmarking on \textbf{150 real legal queries}
    \end{itemize}
    
    \vspace{0.3cm}
    \small
    \textit{This project represents months of iterative development, testing, and refinement.}
    \end{center}
\end{frame}

% ===== SLIDE 16: THANK YOU =====
\begin{frame}
    \begin{center}
        \Huge\textbf{Thank You!}
        
        \vspace{1cm}
        \Large\textcolor{primary}{Questions \& Answers}
        
        \vspace{1cm}
        \normalsize
        \begin{tabular}{ll}
            \textbf{Nguyen My Thong} & 23521527@gm.uit.edu.vn \\
            \textbf{Tran Tuan Kiet} & 23520822@gm.uit.edu.vn \\
        \end{tabular}
        
        \vspace{0.5cm}
        \textcolor{gray}{\small GitHub: Vietnamese-Law-Look-up-and-Advising-System}
    \end{center}
\end{frame}

\end{document}
